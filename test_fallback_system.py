#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script de prueba para el sistema de fallback inteligente
Verifica que Ollama tome el control cuando Groq tiene rate limits
"""

import os
import sys
import logging
import time
from pathlib import Path

# Agregar el directorio raÃ­z al path
sys.path.append(str(Path(__file__).parent.parent))

from src.ai.unified_ai_service import unified_ai_service
from src.ai.ollama_service import ollama_service
from src.ai.intelligent_fallback import get_fallback_stats, enhance_article_with_fallback

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_ollama_availability():
    """Verificar que Ollama estÃ© funcionando"""
    print("ğŸ§ª Probando disponibilidad de Ollama...")
    
    status = ollama_service.check_ollama_status()
    print(f"ğŸ“Š Ollama disponible: {status}")
    
    if status:
        models = ollama_service.get_available_models()
        print(f"ğŸ¤– Modelos disponibles: {len(models)}")
        for model in models:
            print(f"  - {model.get('name', 'Unknown')}")
    
    return status

def test_unified_service():
    """Probar el servicio unificado"""
    print("\nğŸ§ª Probando servicio unificado...")
    
    status = unified_ai_service.get_service_status()
    print(f"ğŸ“Š Estado del servicio:")
    print(f"  - Ollama: {status['ollama']['available']}")
    print(f"  - Groq: {status['groq']['available']}")
    print(f"  - Proveedor preferido: {status['preferred_provider']}")
    
    # Capacidades especializadas
    capabilities = status['capabilities']
    print(f"ğŸ¯ Capacidades especializadas:")
    print(f"  - Razonamiento profundo (DeepSeek): {capabilities['deep_reasoning']}")
    print(f"  - Procesamiento rÃ¡pido (Gemma): {capabilities['fast_processing']}")
    print(f"  - Multiidioma (Qwen): {capabilities['multilingual']}")
    print(f"  - PropÃ³sito general (Llama): {capabilities['general_purpose']}")

def test_analysis_with_fallback():
    """Probar anÃ¡lisis con fallback automÃ¡tico"""
    print("\nğŸ§ª Probando anÃ¡lisis con fallback...")
    
    test_content = """
    TÃTULO: Tensiones geopolÃ­ticas en Europa Oriental
    CONTENIDO: Las recientes decisiones militares han aumentado las tensiones en la regiÃ³n. 
    Varios paÃ­ses han expresado preocupaciÃ³n por la escalada del conflicto. 
    Los lÃ­deres internacionales buscan soluciones diplomÃ¡ticas mientras se mantiene la vigilancia militar.
    """
    
    print("ğŸ”„ Iniciando anÃ¡lisis...")
    start_time = time.time()
    
    try:
        # Usar el servicio unificado (preferirÃ¡ Ollama para evitar rate limits)
        import asyncio
        response = asyncio.run(unified_ai_service.analyze_geopolitical_content(
            content=test_content,
            prefer_local=True
        ))
        
        end_time = time.time()
        duration = end_time - start_time
        
        print(f"âœ… AnÃ¡lisis completado en {duration:.2f}s")
        print(f"ğŸ¤– Proveedor usado: {response.provider}")
        print(f"ğŸ“‹ Modelo: {response.model}")
        print(f"âœ¨ Ã‰xito: {response.success}")
        
        if response.success:
            print(f"ğŸ“„ Resumen: {response.content[:200]}...")
            if response.metadata:
                print(f"ğŸ¯ Metadata disponible: {list(response.metadata.keys())}")
        else:
            print(f"âŒ Error: {response.error}")
            
    except Exception as e:
        print(f"âŒ Error en anÃ¡lisis: {e}")

def test_summary_generation():
    """Probar generaciÃ³n de resÃºmenes"""
    print("\nğŸ§ª Probando generaciÃ³n de resÃºmenes...")
    
    title = "Crisis diplomÃ¡tica internacional"
    content = """
    La situaciÃ³n diplomÃ¡tica se ha complicado tras las declaraciones del ministro.
    Varios embajadores han sido convocados para explicaciones.
    La comunidad internacional observa con preocupaciÃ³n estos desarrollos.
    Se espera una respuesta coordinada en las prÃ³ximas horas.
    """
    
    print("ğŸ”„ Generando resumen...")
    start_time = time.time()
    
    try:
        # Probar resumen rÃ¡pido (deberÃ­a usar Gemma)
        response = unified_ai_service.generate_fast_summary(
            title=title,
            content=content,
            max_words=100
        )
        
        end_time = time.time()
        duration = end_time - start_time
        
        print(f"âœ… Resumen generado en {duration:.2f}s")
        print(f"ğŸ¤– Proveedor: {response.provider}")
        print(f"ğŸ“‹ Modelo: {response.model}")
        print(f"ğŸ“„ Resumen: {response.content}")
        
    except Exception as e:
        print(f"âŒ Error generando resumen: {e}")

def test_deep_analysis():
    """Probar anÃ¡lisis profundo con DeepSeek"""
    print("\nğŸ§ª Probando anÃ¡lisis profundo...")
    
    content = """
    La nueva alianza militar representa un cambio significativo en el equilibrio de poder regional.
    Los analistas sugieren que esto podrÃ­a tener implicaciones de largo plazo para la estabilidad.
    """
    
    question = "Â¿CuÃ¡les son las implicaciones geopolÃ­ticas de esta nueva alianza?"
    
    print("ğŸ”„ Realizando anÃ¡lisis profundo...")
    start_time = time.time()
    
    try:
        import asyncio
        response = asyncio.run(unified_ai_service.perform_deep_analysis(
            content=content,
            question=question
        ))
        
        end_time = time.time()
        duration = end_time - start_time
        
        print(f"âœ… AnÃ¡lisis profundo completado en {duration:.2f}s")
        print(f"ğŸ¤– Proveedor: {response.provider}")
        print(f"ğŸ“‹ Modelo: {response.model}")
        print(f"ğŸ§  ConclusiÃ³n: {response.content}")
        
        if response.metadata:
            confidence = response.metadata.get('confidence', 0)
            print(f"ğŸ¯ Confianza: {confidence:.2f}")
        
    except Exception as e:
        print(f"âŒ Error en anÃ¡lisis profundo: {e}")

def test_fallback_stats():
    """Mostrar estadÃ­sticas de fallback"""
    print("\nğŸ“Š EstadÃ­sticas de fallback:")
    
    try:
        stats = get_fallback_stats()
        
        print(f"  - Total requests Groq: {stats['total_groq_requests']}")
        print(f"  - Rate limits Groq: {stats['groq_rate_limits']}")
        print(f"  - Fallbacks Ollama: {stats['ollama_fallbacks']}")
        print(f"  - Tasa Ã©xito Groq: {stats['groq_success_rate']}%")
        print(f"  - RecomendaciÃ³n: {stats['recommended_action']}")
        
    except Exception as e:
        print(f"âŒ Error obteniendo estadÃ­sticas: {e}")

def main():
    """Ejecutar todas las pruebas"""
    print("ğŸš€ Iniciando pruebas del sistema de fallback inteligente")
    print("=" * 60)
    
    # 1. Verificar Ollama
    ollama_ok = test_ollama_availability()
    
    if not ollama_ok:
        print("âŒ Ollama no disponible. Instalarlo con: python install_ollama.py")
        return
    
    # 2. Estado del servicio unificado
    test_unified_service()
    
    # 3. Pruebas de funcionalidad
    test_analysis_with_fallback()
    test_summary_generation()
    test_deep_analysis()
    
    # 4. EstadÃ­sticas
    test_fallback_stats()
    
    print("\nâœ… Pruebas completadas")
    print("ğŸ’¡ El sistema deberÃ­a usar automÃ¡ticamente Ollama cuando Groq tenga rate limits")

if __name__ == "__main__":
    main()
