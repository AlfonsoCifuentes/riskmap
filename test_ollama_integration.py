#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script de prueba para verificar la integraci√≥n de Ollama con DeepSeek-R1 y Gemma
"""

import sys
import os
import asyncio
import json
from pathlib import Path

# Agregar el directorio del proyecto al path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.ai.ollama_service import ollama_service, OllamaModel
from src.ai.unified_ai_service import unified_ai_service

async def test_ollama_integration():
    """
    Prueba completa de la integraci√≥n de Ollama
    """
    print("üöÄ INICIANDO PRUEBAS DE INTEGRACI√ìN OLLAMA")
    print("=" * 60)
    
    # 1. Verificar estado de Ollama
    print("1Ô∏è‚É£ Verificando estado de Ollama...")
    ollama_running = ollama_service.check_ollama_status()
    print(f"   Ollama ejecut√°ndose: {'‚úÖ' if ollama_running else '‚ùå'}")
    
    if not ollama_running:
        print("‚ùå Ollama no est√° ejecut√°ndose. Por favor, inicia Ollama primero.")
        return False
    
    # 2. Obtener modelos disponibles
    print("\n2Ô∏è‚É£ Verificando modelos disponibles...")
    available_models = ollama_service.get_available_models()
    model_names = [model.get('name', '') for model in available_models]
    
    print(f"   Total de modelos: {len(available_models)}")
    for model in model_names[:5]:  # Mostrar primeros 5
        print(f"   üì¶ {model}")
    
    if len(available_models) > 5:
        print(f"   ... y {len(available_models) - 5} m√°s")
    
    # 3. Verificar modelos espec√≠ficos
    print("\n3Ô∏è‚É£ Verificando modelos especializados...")
    target_models = {
        'DeepSeek-R1': ['deepseek-r1:7b', 'deepseek-r1:1.5b'],
        'Gemma': ['gemma2:2b', 'gemma2:9b'],
        'Qwen': ['qwen:7b', 'qwen2.5-coder:7b'],
        'Llama': ['llama3.1:8b', 'llama3:8b']
    }
    
    available_specialized = {}
    for category, models in target_models.items():
        found = [model for model in models if model in model_names]
        available_specialized[category] = found
        status = '‚úÖ' if found else '‚ùå'
        print(f"   {status} {category}: {found if found else 'No disponible'}")
    
    # 4. Probar servicio unificado
    print("\n4Ô∏è‚É£ Probando servicio unificado...")
    service_status = unified_ai_service.get_service_status()
    
    print(f"   Ollama disponible: {'‚úÖ' if service_status['ollama']['available'] else '‚ùå'}")
    print(f"   Groq disponible: {'‚úÖ' if service_status['groq']['available'] else '‚ùå'}")
    print(f"   Proveedor preferido: {service_status['preferred_provider']}")
    
    capabilities = service_status.get('capabilities', {})
    print(f"   üß† Razonamiento profundo: {'‚úÖ' if capabilities.get('deep_reasoning') else '‚ùå'}")
    print(f"   ‚ö° Procesamiento r√°pido: {'‚úÖ' if capabilities.get('fast_processing') else '‚ùå'}")
    print(f"   üåç Multiidioma: {'‚úÖ' if capabilities.get('multilingual') else '‚ùå'}")
    
    # 5. Pruebas funcionales
    print("\n5Ô∏è‚É£ Ejecutando pruebas funcionales...")
    
    test_content = """
    Ucrania ha solicitado oficialmente el ingreso a la OTAN, lo que ha generado 
    tensiones con Rusia. El presidente Putin ha declarado que esto constituye 
    una amenaza directa a la seguridad nacional rusa y ha movilizado tropas 
    hacia la frontera occidental.
    """
    
    # Prueba 1: An√°lisis est√°ndar
    try:
        print("   üß™ Probando an√°lisis geopol√≠tico...")
        response = await unified_ai_service.analyze_geopolitical_content(
            content=test_content,
            prefer_local=True
        )
        
        if response.success:
            print(f"   ‚úÖ An√°lisis exitoso con {response.provider} ({response.model})")
            print(f"      Resumen: {response.content[:100]}...")
        else:
            print(f"   ‚ùå Error en an√°lisis: {response.error}")
    except Exception as e:
        print(f"   ‚ùå Excepci√≥n en an√°lisis: {e}")
    
    # Prueba 2: Resumen r√°pido (si Gemma est√° disponible)
    if available_specialized.get('Gemma'):
        try:
            print("   üß™ Probando resumen r√°pido con Gemma...")
            response = unified_ai_service.generate_fast_summary(
                title="Tensiones OTAN-Rusia",
                content=test_content,
                max_words=50
            )
            
            if response.success:
                print(f"   ‚úÖ Resumen r√°pido exitoso con {response.provider}")
                print(f"      Resumen: {response.content}")
            else:
                print(f"   ‚ùå Error en resumen: {response.error}")
        except Exception as e:
            print(f"   ‚ùå Excepci√≥n en resumen: {e}")
    
    # Prueba 3: An√°lisis profundo (si DeepSeek est√° disponible)
    if available_specialized.get('DeepSeek-R1'):
        try:
            print("   üß™ Probando an√°lisis profundo con DeepSeek-R1...")
            response = await unified_ai_service.perform_deep_analysis(
                content=test_content,
                question="¬øCu√°les son las implicaciones geopol√≠ticas de esta situaci√≥n?"
            )
            
            if response.success:
                print(f"   ‚úÖ An√°lisis profundo exitoso")
                print(f"      Conclusi√≥n: {response.content[:100]}...")
                if response.metadata:
                    confidence = response.metadata.get('confidence', 'N/A')
                    print(f"      Confianza: {confidence}")
            else:
                print(f"   ‚ùå Error en an√°lisis profundo: {response.error}")
        except Exception as e:
            print(f"   ‚ùå Excepci√≥n en an√°lisis profundo: {e}")
    
    # 6. Resumen final
    print("\n" + "=" * 60)
    print("üìä RESUMEN DE PRUEBAS")
    print("=" * 60)
    
    total_models = len(available_models)
    specialized_count = sum(len(models) for models in available_specialized.values())
    
    print(f"‚úÖ Ollama: {'Funcionando' if ollama_running else 'No disponible'}")
    print(f"üì¶ Modelos totales: {total_models}")
    print(f"üéØ Modelos especializados: {specialized_count}")
    print(f"üîß Servicio unificado: {'Funcionando' if service_status['ollama']['available'] else 'Error'}")
    
    # Recomendaciones
    print("\nüí° RECOMENDACIONES:")
    
    if not available_specialized.get('DeepSeek-R1'):
        print("   üì• Instalar DeepSeek-R1 para an√°lisis profundo: ollama pull deepseek-r1:7b")
    
    if not available_specialized.get('Gemma'):
        print("   üì• Instalar Gemma para procesamiento r√°pido: ollama pull gemma2:2b")
    
    if total_models < 3:
        print("   üì• Se recomienda instalar m√°s modelos para mayor versatilidad")
    
    if ollama_running and total_models >= 3:
        print("   üéâ Sistema listo para producci√≥n!")
    
    return ollama_running and total_models >= 1

def test_model_specific_features():
    """
    Probar caracter√≠sticas espec√≠ficas de cada modelo
    """
    print("\nüî¨ PRUEBAS ESPEC√çFICAS POR MODELO")
    print("=" * 60)
    
    # Prueba con Qwen (si est√° disponible)
    available_models = [model.get('name', '') for model in ollama_service.get_available_models()]
    
    if 'qwen:7b' in available_models:
        print("1Ô∏è‚É£ Probando Qwen 7B...")
        try:
            response = ollama_service.generate_completion(
                prompt="Explica en espa√±ol las relaciones geopol√≠ticas entre China y Estados Unidos",
                model=OllamaModel.QWEN_7B,
                max_tokens=200
            )
            
            if response:
                print(f"   ‚úÖ Qwen respuesta: {response[:150]}...")
            else:
                print("   ‚ùå Qwen no respondi√≥")
        except Exception as e:
            print(f"   ‚ùå Error con Qwen: {e}")
    
    # Prueba con Gemma (si est√° disponible)
    if 'gemma2:2b' in available_models:
        print("\n2Ô∏è‚É£ Probando Gemma 2B...")
        try:
            response = ollama_service.generate_lightweight_summary(
                title="Prueba Gemma",
                content="Este es un texto de prueba para verificar que Gemma puede generar res√∫menes r√°pidos y eficientes.",
                model=OllamaModel.GEMMA2_2B
            )
            
            if response and "error" not in response.lower():
                print(f"   ‚úÖ Gemma resumen: {response}")
            else:
                print("   ‚ùå Gemma fall√≥")
        except Exception as e:
            print(f"   ‚ùå Error con Gemma: {e}")
    
    # Prueba con DeepSeek-R1 (si est√° disponible)
    if 'deepseek-r1:7b' in available_models:
        print("\n3Ô∏è‚É£ Probando DeepSeek-R1...")
        try:
            response = ollama_service.perform_deep_reasoning(
                question="¬øCu√°l es la importancia de la IA en la geopol√≠tica moderna?",
                context="La inteligencia artificial est√° transformando el panorama geopol√≠tico global.",
                model=OllamaModel.DEEPSEEK_R1_7B
            )
            
            if response and response.get('confidence', 0) > 0:
                print(f"   ‚úÖ DeepSeek razonamiento exitoso")
                print(f"      Confianza: {response.get('confidence', 'N/A')}")
                print(f"      Conclusi√≥n: {response.get('conclusion', 'N/A')[:100]}...")
            else:
                print("   ‚ùå DeepSeek fall√≥")
        except Exception as e:
            print(f"   ‚ùå Error con DeepSeek: {e}")

async def main():
    """
    Funci√≥n principal de pruebas
    """
    print("üß™ SUITE DE PRUEBAS - OLLAMA + DEEPSEEK-R1 + GEMMA")
    print("=" * 70)
    
    try:
        # Pruebas principales
        success = await test_ollama_integration()
        
        if success:
            # Pruebas espec√≠ficas
            test_model_specific_features()
            
            print("\n" + "=" * 70)
            print("üéâ PRUEBAS COMPLETADAS EXITOSAMENTE")
            print("   El sistema Ollama est√° listo para usar con RiskMap")
            print("=" * 70)
        else:
            print("\n" + "=" * 70)
            print("‚ùå PRUEBAS FALLARON")
            print("   Revisa la instalaci√≥n de Ollama y los modelos")
            print("=" * 70)
    
    except Exception as e:
        print(f"\n‚ùå Error inesperado en las pruebas: {e}")

if __name__ == "__main__":
    # Ejecutar pruebas
    asyncio.run(main())
