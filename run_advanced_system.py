#!/usr/bin/env python3
"""
Script para ejecutar el Sistema Avanzado de Inteligencia GeopolÃ­tica
Incluye recolecciÃ³n completa, anÃ¡lisis con IA, y poblaciÃ³n de base de datos
"""

import asyncio
import sys
import logging
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.orchestration.advanced_orchestrator import run_advanced_orchestrator

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('advanced_orchestrator.log')
    ]
)

logger = logging.getLogger(__name__)


async def main():
    """FunciÃ³n principal para ejecutar el sistema completo"""
    
    print("ðŸŒ SISTEMA AVANZADO DE INTELIGENCIA GEOPOLÃTICA")
    print("=" * 60)
    print("ðŸ” Capacidades incluidas:")
    print("  â€¢ RecolecciÃ³n RSS/NewsAPI con anÃ¡lisis de IA")
    print("  â€¢ ValidaciÃ³n de imÃ¡genes con modelos de visiÃ³n")
    print("  â€¢ DetecciÃ³n geogrÃ¡fica avanzada (distingue fuente vs contenido)")
    print("  â€¢ Datasets de EnergÃ­a/PetrÃ³leo (EIA, World Bank)")
    print("  â€¢ Datos Militares (SIPRI, HuggingFace)")
    print("  â€¢ Comercio Internacional (World Bank, WTO, IMF)")
    print("  â€¢ Conflictos HistÃ³ricos (UCDP, COW)")
    print("  â€¢ Solo IA real - Sin fallbacks manuales")
    print("=" * 60)
    
    response = input("\nÂ¿Ejecutar recolecciÃ³n completa? (y/N): ")
    if response.lower() != 'y':
        print("âŒ EjecuciÃ³n cancelada")
        return
    
    try:
        logger.info("ðŸš€ Iniciando sistema avanzado...")
        
        # Ejecutar orchestrador avanzado
        results = await run_advanced_orchestrator()
        
        if results:
            print("\nâœ… EJECUCIÃ“N COMPLETADA EXITOSAMENTE")
            print(f"ðŸ“Š Resumen: {results.get('summary', {})}")
            
            # Mostrar detalles por categorÃ­a
            collections = results.get('collections', {})
            for category, data in collections.items():
                print(f"\nðŸ“ {category.upper()}:")
                if 'error' in data:
                    print(f"   âŒ Error: {data['error']}")
                else:
                    sources = data.get('sources_processed', [])
                    print(f"   âœ… Fuentes procesadas: {len(sources)}")
                    if sources:
                        print(f"   ðŸ“‹ Fuentes: {', '.join(sources)}")
            
            # Verificar si hay errores
            errors = results.get('errors', [])
            if errors:
                print(f"\nâš ï¸  ERRORES ENCONTRADOS ({len(errors)}):")
                for error in errors:
                    print(f"   â€¢ {error}")
            
            print(f"\nðŸ—„ï¸  Base de datos actualizada con datos especializados")
            print(f"ðŸ“ˆ Dashboard listo para mostrar datos reales")
            
        else:
            print("\nâŒ EJECUCIÃ“N FALLIDA")
            print("Revisa los logs para mÃ¡s detalles")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸  EjecuciÃ³n interrumpida por el usuario")
        
    except Exception as e:
        logger.error(f"âŒ Error crÃ­tico: {e}")
        print(f"\nðŸ’¥ Error crÃ­tico: {e}")
        print("Revisa advanced_orchestrator.log para detalles completos")


def test_ai_models():
    """Prueba los modelos de IA antes de la ejecuciÃ³n completa"""
    print("\nðŸ§  PROBANDO MODELOS DE IA...")
    print("-" * 40)
    
    try:
        from transformers import pipeline
        import torch
        
        print(f"âœ… PyTorch disponible: {torch.__version__}")
        print(f"ðŸ”¥ CUDA disponible: {torch.cuda.is_available()}")
        
        # Probar modelo de clasificaciÃ³n
        print("ðŸ” Probando clasificaciÃ³n de texto...")
        classifier = pipeline("zero-shot-classification", 
                            model="MoritzLaurer/multilingual-MiniLMv2-L6-mnli-xnli")
        
        result = classifier("Russia invades Ukraine causing international crisis", 
                          ["military conflict", "political tension", "economic crisis"])
        print(f"   Resultado: {result['labels'][0]} ({result['scores'][0]:.3f})")
        
        # Probar modelo de NER
        print("ðŸ·ï¸  Probando extracciÃ³n de entidades...")
        ner = pipeline("ner", model="numind/NuNER-v2.0", aggregation_strategy="simple")
        
        entities = ner("Conflict in Syria affects Lebanon and Jordan")
        locations = [ent['word'] for ent in entities if ent['entity_group'] in ['GPE', 'LOC']]
        print(f"   Ubicaciones detectadas: {locations}")
        
        print("âœ… Todos los modelos funcionan correctamente")
        return True
        
    except Exception as e:
        print(f"âŒ Error probando modelos de IA: {e}")
        return False


def show_menu():
    """Muestra menÃº de opciones"""
    print("\nðŸ“‹ OPCIONES DISPONIBLES:")
    print("1. ðŸ§  Probar modelos de IA")
    print("2. ðŸš€ Ejecutar recolecciÃ³n completa")
    print("3. ðŸ“Š Solo datos de energÃ­a")
    print("4. âš”ï¸  Solo datos militares")
    print("5. ðŸ’¼ Solo datos comerciales")
    print("6. ðŸ“œ Solo conflictos histÃ³ricos")
    print("7. ðŸ“° Solo noticias con IA")
    print("8. âŒ Salir")
    
    return input("\nSelecciona una opciÃ³n (1-8): ")


async def run_specific_collection(collection_type: str):
    """Ejecuta una recolecciÃ³n especÃ­fica"""
    try:
        from src.orchestration.advanced_orchestrator import AdvancedGeopoliticalOrchestrator
        
        orchestrator = AdvancedGeopoliticalOrchestrator()
        
        print(f"\nðŸ”„ Ejecutando recolecciÃ³n: {collection_type.upper()}")
        
        if collection_type == "energy":
            result = await orchestrator.collect_energy_data()
        elif collection_type == "military":
            result = await orchestrator.collect_military_data()
        elif collection_type == "trade":
            result = await orchestrator.collect_trade_data()
        elif collection_type == "historical":
            result = await orchestrator.collect_historical_conflicts()
        elif collection_type == "news":
            result = await orchestrator._collect_news_with_ai_analysis()
        else:
            print("âŒ Tipo de recolecciÃ³n no vÃ¡lido")
            return
        
        print(f"âœ… RecolecciÃ³n completada:")
        print(f"   ðŸ“ Fuentes: {len(result.get('sources_processed', []))}")
        print(f"   ðŸ“Š Estado: {'âœ… Exitoso' if 'error' not in result else 'âŒ Con errores'}")
        
        if 'error' in result:
            print(f"   âš ï¸  Error: {result['error']}")
            
    except Exception as e:
        print(f"âŒ Error en recolecciÃ³n especÃ­fica: {e}")


async def interactive_mode():
    """Modo interactivo con menÃº"""
    while True:
        choice = show_menu()
        
        if choice == "1":
            test_ai_models()
            
        elif choice == "2":
            await main()
            
        elif choice == "3":
            await run_specific_collection("energy")
            
        elif choice == "4":
            await run_specific_collection("military")
            
        elif choice == "5":
            await run_specific_collection("trade")
            
        elif choice == "6":
            await run_specific_collection("historical")
            
        elif choice == "7":
            await run_specific_collection("news")
            
        elif choice == "8":
            print("ðŸ‘‹ Â¡Hasta luego!")
            break
            
        else:
            print("âŒ OpciÃ³n no vÃ¡lida")
        
        input("\nPresiona Enter para continuar...")


if __name__ == "__main__":
    if len(sys.argv) > 1:
        if sys.argv[1] == "--test-ai":
            test_ai_models()
        elif sys.argv[1] == "--full":
            asyncio.run(main())
        elif sys.argv[1] == "--interactive":
            asyncio.run(interactive_mode())
        else:
            print("Opciones: --test-ai, --full, --interactive")
    else:
        # Modo interactivo por defecto
        asyncio.run(interactive_mode())
