#!/usr/bin/env python3
"""
Script de Recolecci√≥n Global Forzada
Asegura recolecci√≥n de noticias en todos los idiomas configurados
"""

import sys
import os
import time
from pathlib import Path

# Add src to path
sys.path.append(str(Path(__file__).parent / 'src'))
sys.path.append(str(Path(__file__).parent))

try:
    from src.data_ingestion.global_news_collector import EnhancedNewsAPICollector, GlobalRSSCollector
    from src.data_ingestion.news_collector import NewsAPICollector
    from src.utils.config import config
except ImportError:
    # Fallback imports
    import sqlite3
    
    class MockConfig:
        def get_database_path(self):
            return 'data/geopolitical_intel.db'
        def get_newsapi_key(self):
            return os.getenv('NEWSAPI_KEY')
    config = MockConfig()
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def force_global_collection():
    """Ejecuta recolecci√≥n forzada en todos los idiomas"""
    
    # Configurar idiomas objetivo con keywords espec√≠ficas
    target_languages = {
        'en': ['conflict', 'war', 'diplomacy', 'geopolitics', 'military', 'crisis'],
        'ru': ['–∫–æ–Ω—Ñ–ª–∏–∫—Ç', '–≤–æ–π–Ω–∞', '–¥–∏–ø–ª–æ–º–∞—Ç–∏—è', '–≤–æ–µ–Ω–Ω—ã–π'],
        'zh': ['ÂÜ≤Á™Å', 'Êàò‰∫â', 'Â§ñ‰∫§', 'ÂÜõ‰∫ã'],
        'ar': ['ÿµÿ±ÿßÿπ', 'ÿ≠ÿ±ÿ®', 'ÿØÿ®ŸÑŸàŸÖÿßÿ≥Ÿäÿ©', 'ÿπÿ≥ŸÉÿ±Ÿä'],
        'fr': ['conflit', 'guerre', 'diplomatie', 'militaire'],
        'de': ['konflikt', 'krieg', 'diplomatie', 'milit√§r']
    }
    
    # Inicializar colectores
    newsapi_collector = NewsAPICollector()
    
    total_collected = 0
    
    for language, keywords in target_languages.items():
        logger.info(f"üåç Recolectando noticias en {language.upper()}...")
        
        lang_total = 0
        
        # Recolecci√≥n por headlines
        try:
            headlines = newsapi_collector.collect_headlines(
                language=language, 
                max_articles=20
            )
            if headlines:
                lang_total += len(headlines)
                logger.info(f"‚úÖ Headlines {language}: {len(headlines)} art√≠culos")
        except Exception as e:
            logger.error(f"‚ùå Error headlines {language}: {e}")
        
        # Recolecci√≥n por keywords
        for keyword in keywords[:2]:  # Limitar a 2 keywords por idioma
            try:
                articles = newsapi_collector.search_everything(
                    query=keyword,
                    language=language,
                    max_articles=15
                )
                if articles:
                    lang_total += len(articles)
                    logger.info(f"‚úÖ Keyword '{keyword}' {language}: {len(articles)} art√≠culos")
                time.sleep(2)  # Rate limiting
            except Exception as e:
                logger.error(f"‚ùå Error keyword '{keyword}' {language}: {e}")
        
        total_collected += lang_total
        logger.info(f"üìä Total {language.upper()}: {lang_total} art√≠culos")
        
        # Pausa entre idiomas
        time.sleep(3)
    
    logger.info(f"üéØ RECOLECCI√ìN COMPLETADA: {total_collected} art√≠culos totales")
    return total_collected

def add_mock_geographic_data():
    """A√±ade datos geogr√°ficos simulados para el heatmap"""
    import sqlite3
    
    try:
        conn = sqlite3.connect(config.get_database_path())
        cursor = conn.cursor()
        
        # Agregar columnas geogr√°ficas si no existen
        try:
            cursor.execute("ALTER TABLE articles ADD COLUMN country TEXT")
            cursor.execute("ALTER TABLE articles ADD COLUMN region TEXT")
            cursor.execute("ALTER TABLE articles ADD COLUMN risk_level TEXT")
        except:
            pass  # Columnas ya existen
        
        # Actualizar art√≠culos existentes con datos geogr√°ficos
        geographic_mapping = {
            'es': [('Spain', 'Europe', 'LOW'), ('Mexico', 'Americas', 'MEDIUM'), ('Argentina', 'Americas', 'LOW')],
            'en': [('USA', 'Americas', 'HIGH'), ('UK', 'Europe', 'MEDIUM'), ('Australia', 'Asia-Pacific', 'LOW')],
            'ru': [('Russia', 'Europe', 'HIGH'), ('Belarus', 'Europe', 'HIGH')],
            'zh': [('China', 'Asia-Pacific', 'HIGH'), ('Taiwan', 'Asia-Pacific', 'HIGH')],
            'ar': [('Saudi Arabia', 'Middle East', 'HIGH'), ('UAE', 'Middle East', 'MEDIUM'), ('Egypt', 'Africa', 'MEDIUM')],
            'fr': [('France', 'Europe', 'MEDIUM')],
            'de': [('Germany', 'Europe', 'LOW')]
        }
        
        for language, locations in geographic_mapping.items():
            for country, region, risk in locations:
                cursor.execute("""
                    UPDATE articles 
                    SET country = ?, region = ?, risk_level = ? 
                    WHERE language = ? AND country IS NULL
                """, (country, region, risk, language))
        
        conn.commit()
        conn.close()
        logger.info("‚úÖ Datos geogr√°ficos a√±adidos exitosamente")
        
    except Exception as e:
        logger.error(f"‚ùå Error a√±adiendo datos geogr√°ficos: {e}")

def main():
    logger.info("üöÄ INICIANDO RECOLECCI√ìN GLOBAL FORZADA")
    
    # Ejecutar recolecci√≥n
    total = force_global_collection()
    
    # A√±adir datos geogr√°ficos
    add_mock_geographic_data()
    
    logger.info("üéâ PROCESO COMPLETADO EXITOSAMENTE")
    
    # Mostrar estad√≠sticas finales
    import sqlite3
    conn = sqlite3.connect(config.get_database_path())
    cursor = conn.cursor()
    
    cursor.execute("SELECT language, COUNT(*) FROM articles GROUP BY language ORDER BY COUNT(*) DESC")
    results = cursor.fetchall()
    
    logger.info("üìä ESTAD√çSTICAS FINALES:")
    for lang, count in results:
        logger.info(f"   {lang.upper()}: {count} art√≠culos")
    
    cursor.execute("SELECT COUNT(*) FROM articles")
    total_db = cursor.fetchone()[0]
    logger.info(f"üìà TOTAL EN BASE DE DATOS: {total_db} art√≠culos")
    
    conn.close()

if __name__ == "__main__":
    main()
