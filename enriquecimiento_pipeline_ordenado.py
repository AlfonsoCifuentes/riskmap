"""
Script de Enriquecimiento Masivo con Pipeline Ordenado
Pipeline: NLP (BERT) â†’ Computer Vision (YOLO) â†’ Fallback AI (Groq/Ollama)
Clasifica riesgo geopolÃ­tico y enriquece todos los artÃ­culos de la BD
"""

import sqlite3
import logging
import os
import sys
import time
import json
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# AÃ±adir directorio principal al path
sys.path.append(str(Path(__file__).parent))

# Base de datos path - actualizada para la BD correcta
DB_PATH = r"E:\Proyectos\VisualStudio\Upgrade_Data_AI\riskmap\data\geopolitical_intel.db"

def verificar_articulos():
    """Verificar cuÃ¡ntos artÃ­culos existen y su estado"""
    try:
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()
            
            # Total de artÃ­culos
            cursor.execute("SELECT COUNT(*) FROM articles")
            total = cursor.fetchone()[0]
            
            # Por estado de enriquecimiento
            cursor.execute("""
                SELECT 
                    COALESCE(enrichment_status, 'null') as status,
                    COUNT(*) as count
                FROM articles 
                GROUP BY enrichment_status
            """)
            
            stats = cursor.fetchall()
            
            print(f"\nğŸ“Š Estado de ArtÃ­culos:")
            print(f"  Total artÃ­culos: {total}")
            print(f"  Por estado:")
            for status, count in stats:
                print(f"    {status}: {count}")
            
            # ArtÃ­culos con anÃ¡lisis de riesgo
            cursor.execute("SELECT COUNT(*) FROM articles WHERE risk_level IS NOT NULL")
            risk_analyzed = cursor.fetchone()[0]
            
            # ArtÃ­culos con anÃ¡lisis de sentimiento
            cursor.execute("SELECT COUNT(*) FROM articles WHERE sentiment_score IS NOT NULL") 
            sentiment_analyzed = cursor.fetchone()[0]
            
            # ArtÃ­culos con anÃ¡lisis de imagen
            cursor.execute("SELECT COUNT(*) FROM articles WHERE visual_analysis_json IS NOT NULL")
            vision_analyzed = cursor.fetchone()[0]
            
            print(f"\nğŸ” AnÃ¡lisis completados:")
            print(f"  Riesgo geopolÃ­tico: {risk_analyzed}/{total}")
            print(f"  AnÃ¡lisis sentimiento: {sentiment_analyzed}/{total}")
            print(f"  Computer Vision: {vision_analyzed}/{total}")
            
            return total
            
    except Exception as e:
        logger.error(f"Error verificando artÃ­culos: {e}")
        return 0

def enrichment_pipeline_step(article_id: int, article_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Pipeline de enriquecimiento ordenado: NLP â†’ CV â†’ Fallback AI
    """
    updates = {}
    pipeline_log = []
    
    try:
        # ====== PASO 1: ANÃLISIS NLP CON BERT ======
        print(f"  ğŸ§  [{article_id}] Paso 1: AnÃ¡lisis NLP con BERT...")
        pipeline_log.append("BERT NLP Analysis")
        
        # Importar anÃ¡lisis de riesgo BERT
        from src.utils.bert_risk_analyzer import BERTRiskAnalyzer
        from src.utils.ai_risk_analyzer import AdvancedRiskAnalyzer
        
        full_text = f"{article_data.get('title', '')} {article_data.get('content', '')}"
        
        # AnÃ¡lisis de riesgo geopolÃ­tico (PRIORITARIO)
        if not article_data.get('risk_level'):
            try:
                risk_analyzer = BERTRiskAnalyzer()
                risk_result = risk_analyzer.analyze_geopolitical_risk(
                    title=article_data.get('title', ''),
                    content=article_data.get('content', ''),
                    context={
                        'source': article_data.get('source', ''),
                        'country': article_data.get('country', ''),
                        'published_at': article_data.get('published_at', '')
                    }
                )
                
                if risk_result and risk_result.get('risk_level'):
                    updates['risk_level'] = risk_result['risk_level']
                    updates['risk_score'] = risk_result.get('risk_score', 0.5)
                    updates['conflict_probability'] = risk_result.get('conflict_probability', 0.5)
                    updates['importance_score'] = risk_result.get('importance_score', 0.5)
                    
                    print(f"    âœ… Riesgo clasificado: {risk_result['risk_level']} (score: {risk_result.get('risk_score', 0):.2f})")
                    
            except Exception as e:
                logger.warning(f"Error en anÃ¡lisis de riesgo BERT: {e}")
        
        # AnÃ¡lisis de sentimiento e importancia
        if not article_data.get('sentiment_score'):
            try:
                from src.ai.bert_service import BERTService
                bert_service = BERTService()
                
                sentiment_result = bert_service.analyze_sentiment(full_text)
                if sentiment_result:
                    updates['sentiment_score'] = sentiment_result.get('score', 0.5)
                    updates['sentiment_label'] = sentiment_result.get('label', 'neutral')
                    
                importance_result = bert_service.calculate_importance(full_text)
                if importance_result:
                    updates['importance_score'] = importance_result.get('score', 0.5)
                    
                print(f"    âœ… Sentimiento: {sentiment_result.get('label', 'N/A')} ({sentiment_result.get('score', 0):.2f})")
                    
            except Exception as e:
                logger.warning(f"Error en anÃ¡lisis de sentimiento: {e}")
        
        # ====== PASO 2: COMPUTER VISION CON YOLO ======
        if article_data.get('image_url') and not article_data.get('visual_analysis_json'):
            print(f"  ğŸ‘ï¸ [{article_id}] Paso 2: Computer Vision con YOLO...")
            pipeline_log.append("Computer Vision Analysis")
            
            try:
                from src.vision_analysis.image_risk_analyzer import ImageRiskAnalyzer
                
                image_analyzer = ImageRiskAnalyzer()
                cv_result = image_analyzer.analyze_image_risk(
                    image_url=article_data['image_url'],
                    article_context={
                        'title': article_data.get('title', ''),
                        'content': article_data.get('content', ''),
                        'risk_level': updates.get('risk_level', article_data.get('risk_level'))
                    }
                )
                
                if cv_result and not cv_result.get('error'):
                    updates['visual_analysis_json'] = json.dumps(cv_result)
                    updates['detected_objects'] = json.dumps(cv_result.get('detected_objects', []))
                    updates['visual_risk_score'] = cv_result.get('visual_risk_score', 0)
                    updates['has_faces'] = cv_result.get('has_people', False)
                    
                    # Combinar riesgo visual con riesgo textual
                    if cv_result.get('visual_risk_score', 0) > 7:
                        current_risk = updates.get('risk_score', article_data.get('risk_score', 0.5))
                        updates['risk_score'] = min(1.0, current_risk + 0.2)  # Aumentar riesgo
                    
                    print(f"    âœ… Objetos detectados: {len(cv_result.get('detected_objects', []))}")
                    print(f"    âœ… Riesgo visual: {cv_result.get('visual_risk_score', 0):.2f}")
                    
            except Exception as e:
                logger.warning(f"Error en Computer Vision: {e}")
        
        # ====== PASO 3: FALLBACK AI (GROQ/OLLAMA) ======
        print(f"  ğŸ¤– [{article_id}] Paso 3: Fallback AI (Groq/Ollama)...")
        pipeline_log.append("Fallback AI Enhancement")
        
        # Solo llenar campos faltantes con AI
        missing_fields = []
        if not article_data.get('country') and not updates.get('country'):
            missing_fields.append('country')
        if not article_data.get('region') and not updates.get('region'):
            missing_fields.append('region')
        if not article_data.get('conflict_type') and not updates.get('conflict_type'):
            missing_fields.append('conflict_type')
        if not article_data.get('summary') and not updates.get('summary'):
            missing_fields.append('summary')
        
        if missing_fields:
            try:
                from src.ai.unified_ai_service import unified_ai_service
                import asyncio
                
                ai_result = asyncio.run(unified_ai_service.analyze_geopolitical_content(
                    content=full_text,
                    prefer_local=True,  # Priorizar Ollama
                    analysis_type="enrichment"
                ))
                
                if ai_result.success and ai_result.metadata:
                    metadata = ai_result.metadata
                    
                    if 'country' in missing_fields and metadata.get('country'):
                        updates['country'] = metadata.get('country', '').split(',')[0]
                    
                    if 'region' in missing_fields and metadata.get('region'):
                        updates['region'] = metadata.get('region', '')
                    
                    if 'conflict_type' in missing_fields and metadata.get('conflict_type'):
                        updates['conflict_type'] = metadata.get('conflict_type', '')
                    
                    if 'summary' in missing_fields and metadata.get('summary'):
                        updates['summary'] = metadata.get('summary', '')
                    
                    print(f"    âœ… Campos completados con AI: {len([f for f in missing_fields if f in updates])}")
                    
            except Exception as e:
                logger.warning(f"Error en Fallback AI: {e}")
        
        # Metadatos de enriquecimiento
        updates['enrichment_status'] = 'completed'
        updates['last_enriched'] = datetime.now().isoformat()
        updates['enrichment_pipeline'] = json.dumps(pipeline_log)
        updates['enrichment_version'] = (article_data.get('enrichment_version') or 0) + 1
        
        return updates
        
    except Exception as e:
        logger.error(f"Error en pipeline de enriquecimiento para artÃ­culo {article_id}: {e}")
        return {
            'enrichment_status': 'error',
            'last_enriched': datetime.now().isoformat(),
            'enrichment_error': str(e)
        }

def enriquecer_lote_articulos(limit: int = 50, force: bool = False) -> Dict[str, Any]:
    """Enriquecer un lote de artÃ­culos siguiendo el pipeline ordenado"""
    
    try:
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()
            
            # Consulta para obtener artÃ­culos que necesitan enriquecimiento
            if force:
                query = "SELECT * FROM articles ORDER BY created_at DESC LIMIT ?"
                params = (limit,)
            else:
                query = """
                    SELECT * FROM articles 
                    WHERE enrichment_status IS NULL 
                       OR enrichment_status = 'pending'
                       OR enrichment_status = 'error'
                    ORDER BY created_at DESC 
                    LIMIT ?
                """
                params = (limit,)
            
            cursor.execute(query, params)
            rows = cursor.fetchall()
            
            if not rows:
                print("â„¹ï¸ No hay artÃ­culos que necesiten enriquecimiento")
                return {'processed': 0, 'success': 0, 'errors': 0}
            
            columns = [desc[0] for desc in cursor.description]
            articles = [dict(zip(columns, row)) for row in rows]
            
            print(f"\nğŸš€ Procesando {len(articles)} artÃ­culos con pipeline ordenado...")
            
            success_count = 0
            error_count = 0
            start_time = time.time()
            
            for i, article in enumerate(articles, 1):
                article_id = article['id']
                print(f"\n[{i}/{len(articles)}] Procesando artÃ­culo {article_id}: {article.get('title', '')[:50]}...")
                
                try:
                    # Ejecutar pipeline de enriquecimiento
                    updates = enrichment_pipeline_step(article_id, article)
                    
                    if updates:
                        # Aplicar updates a la base de datos
                        set_clause = ', '.join([f"{key} = ?" for key in updates.keys()])
                        values = list(updates.values()) + [article_id]
                        
                        cursor.execute(f"UPDATE articles SET {set_clause} WHERE id = ?", values)
                        conn.commit()
                        
                        success_count += 1
                        print(f"  âœ… ArtÃ­culo {article_id} enriquecido: {len(updates)} campos actualizados")
                    else:
                        error_count += 1
                        print(f"  âŒ No se pudo enriquecer artÃ­culo {article_id}")
                        
                except Exception as e:
                    error_count += 1
                    logger.error(f"Error procesando artÃ­culo {article_id}: {e}")
                    
                    # Marcar como error en BD
                    cursor.execute("""
                        UPDATE articles 
                        SET enrichment_status = 'error', 
                            enrichment_error = ?,
                            last_enriched = ?
                        WHERE id = ?
                    """, (str(e), datetime.now().isoformat(), article_id))
                    conn.commit()
            
            total_time = time.time() - start_time
            
            print(f"\nâœ… Enriquecimiento completado:")
            print(f"  Procesados: {len(articles)}")
            print(f"  Exitosos: {success_count}")
            print(f"  Errores: {error_count}")
            print(f"  Tiempo total: {total_time:.2f}s")
            print(f"  Tiempo promedio: {total_time/len(articles):.2f}s por artÃ­culo")
            
            return {
                'processed': len(articles),
                'success': success_count,
                'errors': error_count,
                'processing_time': total_time,
                'average_time': total_time / len(articles) if articles else 0
            }
            
    except Exception as e:
        logger.error(f"Error en enriquecimiento masivo: {e}")
        return {'processed': 0, 'success': 0, 'errors': 1, 'error': str(e)}

def main():
    """FunciÃ³n principal del script"""
    print("ğŸš€ Iniciando Enriquecimiento Masivo con Pipeline Ordenado")
    print(f"ğŸ“‚ Base de datos: {DB_PATH}")
    print(f"ğŸ”„ Pipeline: NLP (BERT) â†’ Computer Vision (YOLO) â†’ Fallback AI (Groq/Ollama)")
    
    # Verificar que la BD existe
    if not Path(DB_PATH).exists():
        logger.error(f"âŒ Base de datos no encontrada: {DB_PATH}")
        return
    
    # Verificar estado inicial
    total_articles = verificar_articulos()
    
    if total_articles == 0:
        logger.warning("âŒ No se encontraron artÃ­culos para procesar")
        return
    
    # Preguntar al usuario
    print(f"\nğŸ“‹ Opciones:")
    print(f"  1. Enriquecer solo artÃ­culos pendientes (recomendado)")
    print(f"  2. Forzar re-enriquecimiento de todos los artÃ­culos")
    
    try:
        opcion = input("\nSeleccionar opciÃ³n (1/2) [1]: ").strip() or "1"
        force = (opcion == "2")
        
        limit = int(input("LÃ­mite de artÃ­culos a procesar [50]: ").strip() or "50")
        
        print(f"\nğŸ¯ ConfiguraciÃ³n:")
        print(f"  Modo: {'Forzar re-enriquecimiento' if force else 'Solo pendientes'}")
        print(f"  LÃ­mite: {limit} artÃ­culos")
        
        confirmar = input("\nÂ¿Continuar? (y/N): ").strip().lower()
        if confirmar not in ['y', 'yes', 's', 'si']:
            print("âŒ OperaciÃ³n cancelada")
            return
        
        # Ejecutar enriquecimiento masivo
        print(f"\n{'='*60}")
        result = enriquecer_lote_articulos(limit=limit, force=force)
        print(f"{'='*60}")
        
        # Verificar estado final
        print("\nğŸ“Š Estado final:")
        verificar_articulos()
        
        if result.get('success', 0) > 0:
            print(f"\nğŸ‰ Â¡Enriquecimiento completado exitosamente!")
            print(f"   {result['success']} artÃ­culos procesados con el pipeline completo")
        
    except KeyboardInterrupt:
        print("\nâŒ OperaciÃ³n interrumpida por el usuario")
    except Exception as e:
        logger.error(f"âŒ Error durante enriquecimiento: {e}")

if __name__ == "__main__":
    main()
